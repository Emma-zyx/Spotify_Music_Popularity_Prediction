{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model \n",
    "from sklearn.metrics import confusion_matrix,mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id', 'artists', 'year', 'release_date', 'duration_ms',\n",
       "       'key', 'mode', 'tempo', 'acousticness', 'danceability', 'energy',\n",
       "       'instrumentalness', 'liveness', 'loudness', 'speechiness', 'valence',\n",
       "       'name', '#vocab', 'avg_word_len', 'uniqueness', 'language', 'comm',\n",
       "       'emotion', 'negative', 'anticipation', 'anger', 'disgust', 'fear',\n",
       "       'joy', 'positive', 'sadness', 'surprise', 'trust', 'popularity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs = pd.read_csv('data_updated.csv')\n",
    "songs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del songs['Unnamed: 0']\n",
    "del songs['id']\n",
    "del songs['release_date']\n",
    "del songs['artists']\n",
    "del songs['name']\n",
    "del songs['emotion']\n",
    "songs['language'] = np.where(songs['language']=='English',1,0)\n",
    "songs['duration_ms'] = songs['duration_ms']/60000\n",
    "songs['popularity'] = np.where(songs['popularity']>=33, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pcolor(songs.corr(), cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             popularity   R-squared:                       0.571\n",
      "Model:                            OLS   Adj. R-squared:                  0.571\n",
      "Method:                 Least Squares   F-statistic:                     8124.\n",
      "Date:                Sun, 20 Dec 2020   Prob (F-statistic):               0.00\n",
      "Time:                        17:42:25   Log-Likelihood:                -51490.\n",
      "No. Observations:              170653   AIC:                         1.030e+05\n",
      "Df Residuals:                  170624   BIC:                         1.033e+05\n",
      "Df Model:                          28                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "const              -26.4011      0.089   -297.251      0.000     -26.575     -26.227\n",
      "year                 0.0137   4.41e-05    309.729      0.000       0.014       0.014\n",
      "duration_ms          0.0031      0.000      7.907      0.000       0.002       0.004\n",
      "key                  0.0006      0.000      2.772      0.006       0.000       0.001\n",
      "mode                -0.0008      0.002     -0.469      0.639      -0.004       0.003\n",
      "tempo            -8.125e-05   2.72e-05     -2.989      0.003      -0.000    -2.8e-05\n",
      "acousticness        -0.0841      0.004    -22.871      0.000      -0.091      -0.077\n",
      "danceability         0.0167      0.006      2.656      0.008       0.004       0.029\n",
      "energy              -0.0310      0.007     -4.708      0.000      -0.044      -0.018\n",
      "instrumentalness    -0.0321      0.003    -10.848      0.000      -0.038      -0.026\n",
      "liveness            -0.0928      0.005    -19.453      0.000      -0.102      -0.083\n",
      "loudness             0.0016      0.000      6.570      0.000       0.001       0.002\n",
      "speechiness         -0.0229      0.006     -4.004      0.000      -0.034      -0.012\n",
      "valence              0.0197      0.004      4.592      0.000       0.011       0.028\n",
      "#vocab              -0.0026      0.000     -6.930      0.000      -0.003      -0.002\n",
      "avg_word_len         0.0022      0.001      4.385      0.000       0.001       0.003\n",
      "uniqueness           0.0231      0.012      1.885      0.059      -0.001       0.047\n",
      "language            -0.0438      0.002    -20.449      0.000      -0.048      -0.040\n",
      "comm                 0.0002      0.001      0.188      0.851      -0.002       0.002\n",
      "negative            -0.0197      0.008     -2.389      0.017      -0.036      -0.004\n",
      "anticipation        -0.0344      0.009     -3.943      0.000      -0.051      -0.017\n",
      "anger                0.0169      0.011      1.545      0.122      -0.005       0.038\n",
      "disgust             -0.0138      0.012     -1.191      0.234      -0.037       0.009\n",
      "fear                -0.0059      0.009     -0.620      0.535      -0.024       0.013\n",
      "joy                  0.0102      0.011      0.960      0.337      -0.011       0.031\n",
      "positive             0.0069      0.008      0.864      0.388      -0.009       0.023\n",
      "sadness              0.0202      0.009      2.186      0.029       0.002       0.038\n",
      "surprise            -0.0244      0.011     -2.273      0.023      -0.045      -0.003\n",
      "trust               -0.0025      0.009     -0.280      0.780      -0.020       0.015\n",
      "==============================================================================\n",
      "Omnibus:                     1166.621   Durbin-Watson:                   0.753\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1240.839\n",
      "Skew:                          -0.179   Prob(JB):                    3.59e-270\n",
      "Kurtosis:                       3.216   Cond. No.                     2.22e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.22e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "X = songs.iloc[0:,0:28]\n",
    "X = sm.add_constant(X)\n",
    "y = songs['popularity']\n",
    "model = sm.OLS(y,X,missing='drop')\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary classification: high popularity vs low popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification(predictions, threshod):\n",
    "    classes = np.zeros_like(predictions)\n",
    "    for i in range(len(classes)):\n",
    "        if predictions[i] < threshod:\n",
    "            classes[i] = 0\n",
    "        else:\n",
    "            classes[i] = 1\n",
    "    return classes\n",
    "\n",
    "def c_m_analysis(true, pred, threshold):\n",
    "    tn, fp, fn, tp = confusion_matrix(true, get_classification(pred, threshold)).ravel()\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    print('Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature set 1: All variables \n",
      "Training R-Square:  0.5695209479307829\n",
      "Testing R-Square:  0.575683386554231\n",
      "Accuracy:  0.8544222204859755\n",
      "None\n",
      "RMSE:  0.3254577108823647\n",
      "\n",
      "\n",
      "Feature set 2: facts + text mining\n",
      "Training R-Square:  0.5649964519339209\n",
      "Testing R-Square:  0.5714816477186171\n",
      "Accuracy:  0.8522540823501836\n",
      "None\n",
      "RMSE:  0.3270651421914429\n",
      "\n",
      "\n",
      "Feature set 3: only facts\n",
      "Training R-Square:  0.5626477352337129\n",
      "Testing R-Square:  0.569357026311765\n",
      "Accuracy:  0.8511602468942886\n",
      "None\n",
      "RMSE:  0.32787494461965394\n",
      "Linear_acc:  0.569357026311765\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(songs, test_size = 0.3, random_state=0) \n",
    "model = linear_model.LinearRegression()\n",
    "\n",
    "# all variables\n",
    "x_train_1 = train.iloc[0:,0:28]\n",
    "y_train = train['popularity']\n",
    "x_test_1 = test.iloc[0:,0:28]\n",
    "y_test = test['popularity']\n",
    "\n",
    "model.fit(x_train_1, y_train)\n",
    "print('Feature set 1: All variables ')\n",
    "print(\"Training R-Square: \", model.score(x_train_1,y_train))\n",
    "print(\"Testing R-Square: \", model.score(x_test_1,y_test))\n",
    "\n",
    "testing_predictions_1  = model.predict(x_test_1)\n",
    "\n",
    "print(c_m_analysis(y_test, testing_predictions_1, 0.5))\n",
    "print('RMSE: ',mean_squared_error(y_test, testing_predictions_1, squared=False))\n",
    "print();print()\n",
    "\n",
    "# facts + text mining\n",
    "x_train_2 = train[['year','duration_ms','key','mode','tempo','#vocab','avg_word_len','uniqueness','language','comm','negative','anticipation','anger','disgust','fear','joy','positive','sadness','surprise','trust']]\n",
    "x_test_2 = test[['year','duration_ms','key','mode','tempo','#vocab','avg_word_len','uniqueness','language','comm','negative','anticipation','anger','disgust','fear','joy','positive','sadness','surprise','trust']]\n",
    "model.fit(x_train_2, y_train)\n",
    "\n",
    "print('Feature set 2: facts + text mining')\n",
    "print(\"Training R-Square: \", model.score(x_train_2,y_train))\n",
    "print(\"Testing R-Square: \", model.score(x_test_2,y_test))\n",
    "\n",
    "testing_predictions_2 = model.predict(x_test_2)\n",
    "\n",
    "print(c_m_analysis(y_test, testing_predictions_2, 0.5))\n",
    "print('RMSE: ',mean_squared_error(y_test, testing_predictions_2, squared=False))\n",
    "print();print()\n",
    "\n",
    "# only facts\n",
    "x_train_3 = train[['year','duration_ms','key','mode','tempo']]\n",
    "x_test_3 = test[['year','duration_ms','key', 'mode','tempo']]\n",
    "\n",
    "model.fit(x_train_3, y_train)\n",
    "print('Feature set 3: only facts')\n",
    "print(\"Training R-Square: \", model.score(x_train_3,y_train))\n",
    "print(\"Testing R-Square: \", model.score(x_test_3,y_test))\n",
    "\n",
    "testing_predictions_3 = model.predict(x_test_3)\n",
    "\n",
    "print(c_m_analysis(y_test, testing_predictions_3, 0.5))\n",
    "print('RMSE: ',mean_squared_error(y_test, testing_predictions_3, squared=False))\n",
    "print('Linear_acc: ', model.score(x_test_3, np.array(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_m_analysis(true, pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(true, pred).ravel()\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    print('Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature set 1: All variables \n",
      "Training R-Square:  0.8501552860024946\n",
      "Testing R-Square (Logistic_acc):  0.8521368856941949\n",
      "RMSE:  0.38452973136781654\n",
      "Accuracy:  0.8521368856941949\n",
      "None\n",
      "\n",
      "\n",
      "Feature set 2: facts + text mining\n",
      "Training R-Square:  0.8477778614899085\n",
      "Testing R-Square (Logistic_acc):  0.8515118368622548\n",
      "RMSE:  0.38534161874594486\n",
      "Accuracy:  0.8515118368622548\n",
      "None\n",
      "\n",
      "\n",
      "Feature set 3: only facts\n",
      "Training R-Square:  0.8461371037277012\n",
      "Testing R-Square (Logistic_acc):  0.8505351980623487\n",
      "RMSE:  0.38660677947709526\n",
      "Accuracy:  0.8505351980623487\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "model = linear_model.LogisticRegression()\n",
    "\n",
    "x = songs.iloc[0:,0:28]\n",
    "y = songs['popularity']\n",
    "\n",
    "x_train_1, x_test_1, y_train_1, y_test_1 = train_test_split(StandardScaler().fit_transform(x),\n",
    "                                                            y, test_size=0.3, random_state=0)\n",
    "model.fit(x_train_1, y_train_1)\n",
    "print('Feature set 1: All variables ')\n",
    "print(\"Training R-Square: \", model.score(x_train_1,y_train_1))\n",
    "print(\"Testing R-Square (Logistic_acc): \", model.score(x_test_1,y_test_1))\n",
    "\n",
    "testing_predictions_1  = model.predict(x_test_1)\n",
    "\n",
    "print('RMSE: ', mean_squared_error(y_test_1, testing_predictions_1, squared=False))\n",
    "print(c_m_analysis(y_test_1, testing_predictions_1))\n",
    "print();print()\n",
    "\n",
    "# facts + text mining\n",
    "x = songs[['year','duration_ms','key','mode','tempo','#vocab','avg_word_len','uniqueness','language','comm','negative','anticipation','anger','disgust','fear','joy','positive','sadness','surprise','trust']]\n",
    "x_train_2, x_test_2, y_train_2, y_test_2 = train_test_split(StandardScaler().fit_transform(x), \n",
    "                                                            y, test_size=0.3, random_state=0)\n",
    "model.fit(x_train_2, y_train_2)\n",
    "\n",
    "print('Feature set 2: facts + text mining')\n",
    "print(\"Training R-Square: \", model.score(x_train_2,y_train_2))\n",
    "print(\"Testing R-Square (Logistic_acc): \", model.score(x_test_2,y_test_2))\n",
    "\n",
    "testing_predictions_2 = model.predict(x_test_2)\n",
    "\n",
    "print('RMSE: ', mean_squared_error(y_test_2, testing_predictions_2, squared=False))\n",
    "print(c_m_analysis(y_test_2, testing_predictions_2))\n",
    "print();print()\n",
    "\n",
    "# only facts\n",
    "x = songs[['year','duration_ms','key','mode','tempo']]\n",
    "x_train_3, x_test_3, y_train_3, y_test_3 = train_test_split(StandardScaler().fit_transform(x),\n",
    "                                                            y, test_size=0.3, random_state=0)\n",
    "model.fit(x_train_3, y_train_3)\n",
    "print('Feature set 3: only facts')\n",
    "print(\"Training R-Square: \", model.score(x_train_3,y_train_3))\n",
    "print(\"Testing R-Square (Logistic_acc): \", model.score(x_test_3,y_test_3))\n",
    "\n",
    "testing_predictions_3 = model.predict(x_test_3)\n",
    "\n",
    "print('RMSE: ', mean_squared_error(y_test_3, testing_predictions_3, squared=False))\n",
    "print(c_m_analysis(y_test_3, testing_predictions_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = pd.read_csv('data_updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "del songs['Unnamed: 0']\n",
    "del songs['id']\n",
    "del songs['release_date']\n",
    "del songs['artists']\n",
    "del songs['name']\n",
    "del songs['emotion']\n",
    "songs['language'] = np.where(songs['language']=='English',1,0)\n",
    "songs['duration_ms'] = songs['duration_ms']/60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature set 1: All variables \n",
      "Training R-Square 0.7530238616441403\n",
      "Testing R-Square 0.7586898455895417\n",
      "RMSE:  10.727309606132794\n",
      "\n",
      "\n",
      "Feature set 2: facts + text mining\n",
      "Training R-Square 0.7450814987528587\n",
      "Testing R-Square 0.7512838133609335\n",
      "RMSE:  10.890681109112752\n",
      "\n",
      "\n",
      "Feature set 3: only facts\n",
      "Training R-Square 0.7420383286714591\n",
      "Testing R-Square 0.7486239450380239\n",
      "RMSE:  10.948760845056416\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(songs, test_size = 0.3, random_state = 0) \n",
    "\n",
    "# all variables\n",
    "x_train_1 = train.iloc[0:,0:28]\n",
    "y_train = train['popularity']\n",
    "x_test_1 = test.iloc[0:,0:28]\n",
    "y_test = test['popularity']\n",
    "\n",
    "model_1 = linear_model.LinearRegression() \n",
    "model_1.fit(x_train_1, y_train)\n",
    "print('Feature set 1: All variables ')\n",
    "print(\"Training R-Square\", model_1.score(x_train_1,y_train))\n",
    "print(\"Testing R-Square\", model_1.score(x_test_1,y_test))\n",
    "\n",
    "testing_predictions_1  = model_1.predict(x_test_1)\n",
    "\n",
    "print('RMSE: ', mean_squared_error(y_test, testing_predictions_1, squared=False))\n",
    "print();print()\n",
    "\n",
    "# facts + text mining\n",
    "x_train_2 = train[['year', 'duration_ms', 'key', 'mode', 'tempo','#vocab', 'avg_word_len', \n",
    "                 'uniqueness','language', 'comm', 'negative', 'anticipation', 'anger', \n",
    "                 'disgust','fear', 'joy', 'positive', 'sadness', 'surprise', 'trust']]\n",
    "x_test_2 = test[['year', 'duration_ms', 'key', 'mode', 'tempo','#vocab', 'avg_word_len', \n",
    "               'uniqueness','language', 'comm', 'negative', 'anticipation', 'anger', \n",
    "               'disgust','fear', 'joy', 'positive', 'sadness', 'surprise', 'trust']]\n",
    "\n",
    "model_2 = linear_model.LinearRegression() \n",
    "model_2.fit(x_train_2, y_train)\n",
    "\n",
    "print('Feature set 2: facts + text mining')\n",
    "print(\"Training R-Square\", model_2.score(x_train_2,y_train))\n",
    "print(\"Testing R-Square\", model_2.score(x_test_2,y_test))\n",
    "\n",
    "testing_predictions_2 = model_2.predict(x_test_2)\n",
    "\n",
    "print('RMSE: ', mean_squared_error(y_test, testing_predictions_2, squared=False))\n",
    "print();print()\n",
    "\n",
    "# only facts\n",
    "x_train_3 = train[['year', 'duration_ms', 'key', 'mode', 'tempo']]\n",
    "x_test_3 = test[['year', 'duration_ms', 'key', 'mode', 'tempo']]\n",
    "\n",
    "model_3 = linear_model.LinearRegression() \n",
    "model_3.fit(x_train_3, y_train)\n",
    "print('Feature set 3: only facts')\n",
    "print(\"Training R-Square\", model_3.score(x_train_3,y_train))\n",
    "print(\"Testing R-Square\", model_3.score(x_test_3,y_test))\n",
    "\n",
    "testing_predictions_3 = model_3.predict(x_test_3)\n",
    "\n",
    "print('RMSE: ', mean_squared_error(y_test, testing_predictions_3, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
